{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd563bfd-ef08-4f84-a4b4-9dadf120b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jams\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581abcd3-890c-48c2-be0e-ec42b95e6719",
   "metadata": {},
   "source": [
    "## Exploring the Structure of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c285e2e-aac9-4502-8148-abac1ed827a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your folder containing the two subfolders \"annotations\" and \"audio_hex-pickup_debleeded\"\n",
    "base_dir = r\"C:\\Users\\...\" \n",
    "\n",
    "audio_dir = os.path.join(base_dir, \"audio_hex-pickup_debleeded\")  # Path to the \"audio_hex-pickup_debleeded\" subfolder\n",
    "annotation_dir = os.path.join(base_dir, \"annotation\")  # Path to the \"annotation\" subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ab749-a5f3-4379-b3c2-1f0d10ad8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with an audio file\n",
    "audio_file = os.path.join(audio_dir, \"example.wav\")  # Replace \"example.wav\" with an actual filename, e.g., \"00_Jazz3-137-Eb_comp_hex_cln.wav\"\n",
    "\n",
    "# Load the audio\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Display information\n",
    "print(f\"Duration: {librosa.get_duration(y=y, sr=sr):.2f} seconds\")\n",
    "print(f\"Sampling rate: {sr} Hz\")\n",
    "\n",
    "# # Plot the waveform\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# librosa.display.waveshow(y, sr=sr)\n",
    "# plt.title(\"Waveform\")\n",
    "# plt.xlabel(\"Time (s)\")\n",
    "# plt.ylabel(\"Amplitude\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90309d-7209-4fc6-8bcd-46f6e13d340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with a JAMS file\n",
    "jams_file = os.path.join(annotation_dir, \"example.jams\")  # Replace \"example.jams\" with an actual filename, e.g., \"00_Jazz3-137-Eb_comp.jams\"\n",
    "\n",
    "# Load the file\n",
    "jams = jams.load(jams_file)\n",
    "\n",
    "# # Display available metadata and annotations\n",
    "# print(\"Available annotations:\", [annotation.namespace for annotation in jams.annotations])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0505eb-43f8-4ca4-b8b6-686ce427a513",
   "metadata": {},
   "source": [
    "## Preprocessing and Extracting Useful Annotations as CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc315a57-664e-49be-8faa-f8427e68f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output folder to store the useful annotations as CSV files\n",
    "output_folder = r\"C:\\Users\\....\"\n",
    "\n",
    "# Create subfolders for the labels\n",
    "os.makedirs(os.path.join(output_folder, \"pitch_contour\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_folder, \"midi_notes\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_folder, \"onsets\"), exist_ok=True)\n",
    "\n",
    "# Loop through all .jams files\n",
    "for filename in os.listdir(annotation_dir):\n",
    "    if filename.endswith(\".jams\"):\n",
    "        # Load the JAMS file\n",
    "        file_path = os.path.join(annotation_dir, filename)\n",
    "        jams_data = jams.load(file_path)\n",
    "\n",
    "        # Extract annotations\n",
    "        pitch_contours = []\n",
    "        midi_notes = []\n",
    "        note_onsets = []\n",
    "\n",
    "        for annotation in jams_data.annotations:\n",
    "            if annotation.namespace == \"pitch_contour\":\n",
    "                for obs in annotation.data:\n",
    "                    pitch_contours.append({\n",
    "                        \"time\": obs.time,\n",
    "                        \"index\": obs.value.get(\"index\", None),\n",
    "                        \"frequency\": obs.value.get(\"frequency\", None),\n",
    "                        \"voiced\": obs.value.get(\"voiced\", None),\n",
    "                    })\n",
    "            elif annotation.namespace == \"note_midi\":\n",
    "                for obs in annotation.data:\n",
    "                    midi_notes.append({\n",
    "                        \"time\": obs.time,\n",
    "                        \"duration\": obs.duration,\n",
    "                        \"note\": obs.value,  # obs.value is a float for MIDI notes\n",
    "                    })\n",
    "                    note_onsets.append({\"time\": obs.time})\n",
    "\n",
    "        # Save the labels into separate files\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        # 1. Pitch Contour\n",
    "        with open(os.path.join(output_folder, \"pitch_contour\", f\"{base_name}_pitch_contour.csv\"), \"w\", newline=\"\") as csvfile:\n",
    "            fieldnames = [\"time\", \"index\", \"frequency\", \"voiced\"]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(pitch_contours)\n",
    "\n",
    "        # 2. MIDI Notes\n",
    "        with open(os.path.join(output_folder, \"midi_notes\", f\"{base_name}_midi_notes.csv\"), \"w\", newline=\"\") as csvfile:\n",
    "            fieldnames = [\"time\", \"duration\", \"note\"]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(midi_notes)\n",
    "\n",
    "        # 3. Note Onsets\n",
    "        with open(os.path.join(output_folder, \"onsets\", f\"{base_name}_onsets.csv\"), \"w\", newline=\"\") as csvfile:\n",
    "            fieldnames = [\"time\"]\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(note_onsets)\n",
    "\n",
    "        # print(f\"Labels generated for: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ddaf3-00bf-4c4e-a06a-089528720745",
   "metadata": {},
   "source": [
    "### Generation of Target Matrices (yo, yn, yp) from Previously Extracted Annotations: pitch_contour, midi_notes, onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab28e0-e649-4da9-85f2-ad060f81f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "hop_size = 0.011  # 11 ms between two frames\n",
    "fmin = 27.5  # Minimum frequency (A0) in Hz\n",
    "midi_min = 21  # Minimum MIDI note (A0)\n",
    "num_semitones = 88  # Total number of semitones (piano A0-C8)\n",
    "bins_per_semitone = 3\n",
    "bins_per_octave = bins_per_semitone * 12\n",
    "\n",
    "# Function to generate binary matrices for an audio file\n",
    "def generate_matrices(onsets_path, midi_notes_path, pitch_contour_path, save_path):\n",
    "    # Read the data\n",
    "    onsets = pd.read_csv(onsets_path)\n",
    "    midi_notes = pd.read_csv(midi_notes_path)\n",
    "    pitch_contour = pd.read_csv(pitch_contour_path)\n",
    "    \n",
    "    # Calculate the total duration of the audio\n",
    "    duration = max(\n",
    "        onsets['time'].max(),\n",
    "        midi_notes['time'].max() + midi_notes['duration'].max(),\n",
    "        pitch_contour['time'].max()\n",
    "    )\n",
    "    num_frames = int(duration / hop_size)\n",
    "    num_bins_yn_yo = num_semitones\n",
    "    num_bins_yp = num_semitones * bins_per_semitone\n",
    "\n",
    "    # Initialize matrices\n",
    "    Yo = np.zeros((num_frames, num_bins_yn_yo))\n",
    "    Yn = np.zeros((num_frames, num_bins_yn_yo))\n",
    "    Yp = np.zeros((num_frames, num_bins_yp))\n",
    "    \n",
    "    # Generate Yn (note activations) and Yo (note onsets)\n",
    "    for _, row in midi_notes.iterrows():\n",
    "        onset_time = row['time']\n",
    "        duration = row['duration']\n",
    "        pitch = row['note']  # Note in MIDI format\n",
    "        \n",
    "        # Convert time to frame indices\n",
    "        start_frame = int(onset_time / hop_size)\n",
    "        end_frame = int((onset_time + duration) / hop_size)\n",
    "        \n",
    "        # Convert MIDI note to bin index\n",
    "        bin_index = int(pitch - midi_min)\n",
    "        \n",
    "        # Activate Yn for frames where the note is active\n",
    "        if 0 <= bin_index < num_bins_yn_yo and start_frame < num_frames:\n",
    "            Yn[start_frame:end_frame, bin_index] = 1  # Activate bins for the duration\n",
    "            \n",
    "            # Activate Yo only at the note onset (precise instant)\n",
    "            Yo[start_frame, bin_index] = 1  # Note onset for a specific pitch\n",
    "    \n",
    "    # Generate Yp (multipitch)\n",
    "    for _, row in pitch_contour.iterrows():\n",
    "        time = row['time']\n",
    "        frequency = row['frequency']\n",
    "        \n",
    "        # Convert time to frame index\n",
    "        time_frame = int(time / hop_size)\n",
    "        \n",
    "        # Ensure the time index is within bounds\n",
    "        if not (0 <= time_frame < num_frames):\n",
    "            print(f\"Time frame out of bounds: {time_frame} (Max duration: {num_frames})\")\n",
    "            continue\n",
    "\n",
    "        # Convert frequency to bin index\n",
    "        if frequency > 0:  # Ignore zero frequencies\n",
    "            bin_index = int((np.log2(frequency / fmin)) * bins_per_octave)\n",
    "            \n",
    "            # Normalize out-of-bounds indices\n",
    "            bin_index = max(0, min(bin_index, num_bins_yp - 3))\n",
    "            Yp[time_frame, bin_index:bin_index+3] = 1\n",
    "    \n",
    "    # Save the matrices\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    np.save(os.path.join(save_path, \"Yo.npy\"), Yo)\n",
    "    np.save(os.path.join(save_path, \"Yn.npy\"), Yn)\n",
    "    np.save(os.path.join(save_path, \"Yp.npy\"), Yp)\n",
    "    # print(f\"Matrices saved in {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f4cdf7-a737-42b0-88f2-7f9a35feba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the path containing the extracted annotations: pitch_contour, midi_notes, onsets for train and test\n",
    "base_path = r\"C:\\Users\\....\"  \n",
    "subdirs = [\"train\", \"test\"]\n",
    "\n",
    "# Loop through files in train and test directories\n",
    "for subdir in subdirs:\n",
    "    onsets_dir = os.path.join(base_path, subdir, \"labels\", \"onsets\")\n",
    "    midi_notes_dir = os.path.join(base_path, subdir, \"labels\", \"midi_notes\")\n",
    "    pitch_contour_dir = os.path.join(base_path, subdir, \"labels\", \"pitch_contour\")\n",
    "    save_dir = os.path.join(base_path, subdir, \"matrices\")\n",
    "    \n",
    "    # Process all corresponding CSV files\n",
    "    for file_name in os.listdir(onsets_dir):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_id = os.path.splitext(file_name)[0]  # Extract the file ID\n",
    "            onsets_path = os.path.join(onsets_dir, file_name)\n",
    "            midi_notes_path = os.path.join(midi_notes_dir, f\"{file_id}.csv\")\n",
    "            pitch_contour_path = os.path.join(pitch_contour_dir, f\"{file_id}.csv\")\n",
    "            save_path = os.path.join(save_dir, file_id)\n",
    "            \n",
    "            # Check that all required files exist\n",
    "            if os.path.exists(onsets_path) and os.path.exists(midi_notes_path) and os.path.exists(pitch_contour_path):\n",
    "                # print(f\"Processing files for {file_id}...\")\n",
    "                generate_matrices(onsets_path, midi_notes_path, pitch_contour_path, save_path)\n",
    "            else:\n",
    "                print(f\"Missing files for {file_id}. Skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447a593-541e-4a9f-acee-0fb1342e8d37",
   "metadata": {},
   "source": [
    "### Display the time-frequency target matrices (for the total duration of the audio files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f754522-6a96-47e6-9e68-516bee41b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store the target matrices\n",
    "base_dir = r\"C:\\Users\\...\"  \n",
    "\n",
    "# Load all subdirectories (containing the matrices)\n",
    "all_files = []\n",
    "for subdir in os.listdir(base_dir):\n",
    "    subdir_path = os.path.join(base_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Find Yo.npy, Yn.npy, Yp.npy files\n",
    "        files = {\n",
    "            \"Yo\": os.path.join(subdir_path, \"Yo.npy\"),\n",
    "            \"Yn\": os.path.join(subdir_path, \"Yn.npy\"),\n",
    "            \"Yp\": os.path.join(subdir_path, \"Yp.npy\"),\n",
    "        }\n",
    "        if all(os.path.exists(f) for f in files.values()):\n",
    "            all_files.append(files)\n",
    "\n",
    "# Check if any files are available\n",
    "if len(all_files) == 0:\n",
    "    print(\"No matrix files found.\")\n",
    "else:\n",
    "    # Select 2 or 3 matrices randomly\n",
    "    selected_files = random.sample(all_files, min(3, len(all_files)))\n",
    "\n",
    "    # Display the matrices\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for idx, file_set in enumerate(selected_files):\n",
    "        for matrix_type, path in file_set.items():\n",
    "            matrix = np.load(path)\n",
    "            \n",
    "            # Display the shape of the matrix\n",
    "            print(f\"{matrix_type} (file: {os.path.basename(path)}) - Shape: {matrix.shape}\")\n",
    "            \n",
    "            # Plot the matrix\n",
    "            plt.subplot(len(selected_files), 3, idx * 3 + list(file_set.keys()).index(matrix_type) + 1)\n",
    "            plt.imshow(matrix.T, aspect=\"auto\", origin=\"lower\", cmap=\"hot\")\n",
    "            plt.colorbar(label=\"Value\")\n",
    "            plt.title(f\"{matrix_type} (file: {os.path.basename(path)})\")\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Frequency bins\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
